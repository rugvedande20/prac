{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "758eb740-8598-4213-8778-44ef540bb663",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = \"A paragraph is a distinct section of writing that focuses on a single idea or topic, typically consisting of several sentences. It is a way to organize text and help the reader follow the author's thoughts by clearly signaling shifts in ideas and giving the reader a break. \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4e462eaf-86c4-401b-878a-88503b9a7a93",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "237822ad-6429-4fb6-8b6e-763c7892b29e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "691e7879-3d67-4ce7-a0c3-dd38615a78cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['A', 'paragraph', 'is', 'a', 'distinct', 'section', 'of', 'writing', 'that', 'focuses', 'on', 'a', 'single', 'idea', 'or', 'topic', ',', 'typically', 'consisting', 'of', 'several', 'sentences', '.', 'It', 'is', 'a', 'way', 'to', 'organize', 'text', 'and', 'help', 'the', 'reader', 'follow', 'the', 'author', \"'s\", 'thoughts', 'by', 'clearly', 'signaling', 'shifts', 'in', 'ideas', 'and', 'giving', 'the', 'reader', 'a', 'break', '.']\n"
     ]
    }
   ],
   "source": [
    "tokens = word_tokenize(doc)\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f6c6c966-e7a1-4717-be49-d0516d3cf690",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('A', 'DT'), ('paragraph', 'NN'), ('is', 'VBZ'), ('a', 'DT'), ('distinct', 'JJ'), ('section', 'NN'), ('of', 'IN'), ('writing', 'VBG'), ('that', 'DT'), ('focuses', 'VBZ'), ('on', 'IN'), ('a', 'DT'), ('single', 'JJ'), ('idea', 'NN'), ('or', 'CC'), ('topic', 'NN'), (',', ','), ('typically', 'RB'), ('consisting', 'VBG'), ('of', 'IN'), ('several', 'JJ'), ('sentences', 'NNS'), ('.', '.'), ('It', 'PRP'), ('is', 'VBZ'), ('a', 'DT'), ('way', 'NN'), ('to', 'TO'), ('organize', 'VB'), ('text', 'NN'), ('and', 'CC'), ('help', 'VB'), ('the', 'DT'), ('reader', 'NN'), ('follow', 'VBP'), ('the', 'DT'), ('author', 'NN'), (\"'s\", 'POS'), ('thoughts', 'NNS'), ('by', 'IN'), ('clearly', 'RB'), ('signaling', 'VBG'), ('shifts', 'NNS'), ('in', 'IN'), ('ideas', 'NNS'), ('and', 'CC'), ('giving', 'VBG'), ('the', 'DT'), ('reader', 'NN'), ('a', 'DT'), ('break', 'NN'), ('.', '.')]\n"
     ]
    }
   ],
   "source": [
    "from nltk import pos_tag\n",
    "tags = pos_tag(tokens)\n",
    "print(tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "938552f0-66f6-42f6-90a3-048d7fe2bccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "s_words = set(stopwords.words('English'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "de137bc1-4c84-4c54-b133-11059a89c010",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Tokens Without Stopwords: ['paragraph', 'distinct', 'section', 'writing', 'focuses', 'single', 'idea', 'topic', ',', 'typically', 'consisting', 'several', 'sentences', '.', 'way', 'organize', 'text', 'help', 'reader', 'follow', 'author', \"'s\", 'thoughts', 'clearly', 'signaling', 'shifts', 'ideas', 'giving', 'reader', 'break', '.']\n",
      "\n",
      " Tokens Without Stopwords and Punctuation: ['paragraph', 'distinct', 'section', 'writing', 'focuses', 'single', 'idea', 'topic', 'typically', 'consisting', 'several', 'sentences', 'way', 'organize', 'text', 'help', 'reader', 'follow', 'author', \"'s\", 'thoughts', 'clearly', 'signaling', 'shifts', 'ideas', 'giving', 'reader', 'break']\n"
     ]
    }
   ],
   "source": [
    "tokens_without_stopwords = [word for word in tokens if word.lower() not in s_words]\n",
    "print(\"\\n Tokens Without Stopwords:\",tokens_without_stopwords)\n",
    "import string\n",
    "tokens_without_stopwords_and_punctuation = [word for word in tokens if word.lower() not in s_words and word not in string.punctuation]\n",
    "print(\"\\n Tokens Without Stopwords and Punctuation:\",tokens_without_stopwords_and_punctuation)\n",
    "tswp = tokens_without_stopwords_and_punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9f43d7dc-6196-4186-9698-0dd646af4c1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['paragraph', 'distinct', 'section', 'write', 'focus', 'singl', 'idea', 'topic', 'typic', 'consist', 'sever', 'sentenc', 'way', 'organ', 'text', 'help', 'reader', 'follow', 'author', \"'s\", 'thought', 'clearli', 'signal', 'shift', 'idea', 'give', 'reader', 'break']\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "Porter = PorterStemmer()\n",
    "var_porter = [Porter.stem(word) for word in tswp]\n",
    "print(var_porter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "531a783d-cf2f-474b-bb5b-38513c3bb758",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['paragraph', 'distinct', 'section', 'write', 'focus', 'singl', 'idea', 'topic', 'typic', 'consist', 'sever', 'sentenc', 'way', 'organ', 'text', 'help', 'reader', 'follow', 'author', \"'s\", 'thought', 'clear', 'signal', 'shift', 'idea', 'give', 'reader', 'break']\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import SnowballStemmer\n",
    "Snowball = SnowballStemmer('english')\n",
    "var_snowball = [Snowball.stem(word) for word in tswp]\n",
    "print(var_snowball)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "660b083a-fa00-4b85-8180-5c486380f6c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['paragraph', 'distinct', 'section', 'write', 'focus', 'single', 'idea', 'topic', 'typically', 'consist', 'several', 'sentence', 'way', 'organize', 'text', 'help', 'reader', 'follow', 'author', \"'s\", 'thoughts', 'clearly', 'signal', 'shift', 'ideas', 'give', 'reader', 'break']\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "lemma = WordNetLemmatizer()\n",
    "lemmatized = [lemma.lemmatize(word, pos='v') for word in tswp]\n",
    "print(lemmatized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "79e94287-2857-4b30-9415-4685ca1c679f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4323581b-7066-4c21-a148-8187b23301ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = [\"The old library creaked with every step, hiding secrets between its dusty shelves.\",\n",
    "\"A bright blue kite danced wildly in the afternoon sky above the park.\",\n",
    "\"She poured a second cup of coffee, staring at the rain tapping against the windowpane.\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d2b070d4-f23d-4a24-83ff-7036892b5421",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_matrix = vectorizer.fit_transform(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4764868e-8399-4a00-9b48-bda4d8e12661",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF Representation:\n",
      "   above  afternoon  against    at  between  blue  bright  coffee  creaked  \\\n",
      "0    0.0        0.0     0.00  0.00     0.28   0.0     0.0    0.00     0.28   \n",
      "1    0.3        0.3     0.00  0.00     0.00   0.3     0.3    0.00     0.00   \n",
      "2    0.0        0.0     0.27  0.27     0.00   0.0     0.0    0.27     0.00   \n",
      "\n",
      "    cup  ...   she  shelves  sky  staring  step  tapping   the  wildly  \\\n",
      "0  0.00  ...  0.00     0.28  0.0     0.00  0.28     0.00  0.17     0.0   \n",
      "1  0.00  ...  0.00     0.00  0.3     0.00  0.00     0.00  0.35     0.3   \n",
      "2  0.27  ...  0.27     0.00  0.0     0.27  0.00     0.27  0.32     0.0   \n",
      "\n",
      "   windowpane  with  \n",
      "0        0.00  0.28  \n",
      "1        0.00  0.00  \n",
      "2        0.27  0.00  \n",
      "\n",
      "[3 rows x 35 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame(tfidf_matrix.toarray(), columns=vectorizer.get_feature_names_out())\n",
    "print(\"TF-IDF Representation:\")\n",
    "print(df.round(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a878a378-1f22-4a0b-b0a1-e9c606019719",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
